import streamlit as st
import numpy as np
import PIL.Image as Image
import os
import shutil
import requests
import json
import uuid
import base64
from glob import glob
from omegaconf import OmegaConf
import time 


#add_bg_from_local("/home/storage/frontend/logo.jpeg")
#Read port config file
port_config = OmegaConf.load("/home/storage/config.yaml")

st.sidebar.header("Select a demo")
app_mode = st.sidebar.selectbox(
    "Options",
    ["Info", "Image Generation", "Image Modification", "Upscaling"],
)
if app_mode == "Info":
    st.markdown("# Stable Diffusion Version 2")
    st.write(
        """ ### What is Stable Diffusion Image Generator?

Stable Diffusion Image Generator (SDIG) is an AI-powered technology used to generate visuals from text. This technology uses Computer Vision algorithms and NLP technology to analyze the text input and generate visuals from it. SDIG is a revolutionary technology that has made it easier for artists to create original artwork with minimal effort. The visuals generated by SDIG are unique and one-of-a-kind, making it perfect for creating original artwork. SDIG is also able to generate visuals from different types of text, including poetry, lyrics, and stories.

### How Stable Diffusion Image Generator is Transforming Various Industries?

Stable Diffusion Image Generator is transforming various industries with its revolutionary technology.
Here are some of the ways that SDIG is transforming various industries:

**Advertising and Marketing:** AI-generated images from text can be used to create unique visuals for advertising and **marketing campaigns.** These visuals can be used to promote products and services in a more engaging way.

**Web Design:** AI-generated images from text can be used to create unique visuals for websites. These visuals can help make websites more visually appealing and engaging.

**Graphic Design:** AI-generated images from text can be used to create unique visuals for graphic design projects. These visuals can help make designs more dynamic and engaging.
"""
    )


if app_mode == "Image Generation":
    st.markdown("# Stable Diffusion Version 2 - Image Generation")
    #Read input prompt and user configs 
    Prompt = st.text_input(
        "Prompt",
        value=" portrait photo of a old man crying, Tattles, sitting on bed, guages in ears, looking away, serious eyes, 50mm portrait photography, hard rim lighting photographyâ€“beta â€“ar 2:3 â€“beta â€“upbeta",
        key="Description_key",
    )
    c1, c2, c3, c4, c5 = st.columns([1, 1, 1, 1, 1], gap="small")
    with c1:
        w = st.number_input("Width", value=768, step=64, key="Width_key")
    with c2:
        h = st.number_input("Height", value=768, step=64, key="Height_key")
    with c3:
        s = st.number_input("Seed", value=42, step=1, key="Seed_key")
    with c4:
        samples = st.number_input("samples", value=3, step=1, key="samples_key")

    with c5:
        n_iter = st.number_input("iterations", value=3, step=1, key="iterations_key")

    run = st.button("Generate")
    if run and Prompt:
        # make request body and send it
        payload = {
            "name": Prompt,
            "w": w,
            "h": h,
            "samples": samples,
            "n_iter": n_iter,
            "seed": s,
        }
        with st.spinner("Generating ..."):
            start = time.time()
            res = requests.post(
                f"http://{port_config.model_ports.stablediff2[-1]}:8505/txt2img",
                data=json.dumps(payload),
            )
            end = time.time()
        try:
            response = res.json()
            zip_path = response["response"]["path"]
            grid_path = response["response"]["grid_path"]
            st.success('Successful!')
            st.image(Image.open(response["response"]["image"]))

            payload = {
                    "req_type": "Stable Diffusion version2 - txt2img",
                    "prompt": Prompt,
                    "runtime": (end - start)
                    }

            db_req = requests.post(
                f"http://{port_config.model_ports.db[-1]}:8509/insert",
                data=json.dumps(payload),
            )
            # enable user to download generated images
            with open(zip_path + ".zip", "rb") as file:
                btn = st.download_button(
                    label="Download Samples",
                    data=file,
                    file_name=zip_path + ".zip",
                )
                # delete generated files/directories
            shutil.rmtree(zip_path)
            shutil.rmtree(grid_path)
            os.remove(zip_path + ".zip")
        except NameError:
            st.error('Unsuccessful. Encountered an error. Try again!', icon="ðŸš¨")
        except json.decoder.JSONDecodeError: 
            st.error('Unsuccessful. Encountered an error. Please try again!', icon="ðŸš¨")

        
# image to image

elif app_mode == "Image Modification":
    st.markdown("# Stable Diffusion Version 2 - Image Modification")
    # upload input image
    uploaded_file = st.file_uploader(
        "Upload a image: image should be larger than 256x256",
        type=["jpg", "jpeg", "png"],
    )
    if uploaded_file:
        st.image(uploaded_file)
        #check if image size is not smaller than 256*256
        image = Image.open(uploaded_file)
        w, h = image.size
        if w < 256 or h < 256:
            uploaded_file = False
            st.text(
                f"loaded input image of size ({w}, {h}). Image should be larger than 256x256"
            )
    if uploaded_file:
        # get the prompt and configuration from user
        prompt = st.text_input(
            "Prompt",
            value=" A boat is sailing in a fictional ocean in front of mountains.",
            key="Description_key",
        )
        c1, c2, c3, c4 = st.columns([1, 1, 1, 1], gap="small")
        with c1:
            strng = st.number_input(
                "Strength (0,1):",
                value=0.8,
                step=0.01,
                format="%.2f",
                key=str(uuid.uuid4()),
            )
        with c2:
            s = st.number_input("Seed", value=42, step=1, key="Seed_key")
        with c3:
            samples = st.number_input("samples", value=1, step=1, key="samples_key")
        with c4:
            n_iter = st.number_input(
                "iterations", value=3, step=1, key="iterations_key"
            )

        run = st.button("Generate")
        if prompt and run:
            #make request body and send it
            files = {"files": uploaded_file.getvalue()}
            payload = {
                "name": prompt,
                "samples": samples,
                "n_iter": n_iter,
                "seed": s,
                "strength": strng,
            }
            with st.spinner("Generating ..."):
                start = time.time()
                res = requests.post(
                    f"http://{port_config.model_ports.stablediff2[-1]}:8505/img2img",
                    params=payload,
                    files=files,
                )
                end = time.time()
            try:
                # get the respons includes paths to generated images
                response = res.json()
                zip_path = response["response"]["path"]
                grid_path = response["response"]["grid_path"]
                st.success('Successful!')
                payload = {
                    "req_type": "Stable Diffusion version2 - img2img",
                    "prompt":prompt,
                    "runtime": (end - start)
                    }

                db_req = requests.post(
                f"http://{port_config.model_ports.db[-1]}:8509/insert",
                data=json.dumps(payload),
            )
                st.image(Image.open(response["response"]["image"]))
                # enable user to download generated images 
                with open(zip_path + ".zip", "rb") as file:
                    btn = st.download_button(
                        label="Download Samples",
                        data=file,
                        file_name=zip_path + ".zip",
                    )
                    # delete generated images and directories
                shutil.rmtree(zip_path)
                shutil.rmtree(grid_path)
                os.remove(zip_path + ".zip")
            except NameError:
                st.error('Unsuccessful. Encountered an error. Try again!', icon="ðŸš¨")
            except json.decoder.JSONDecodeError: 
                st.error('Unsuccessful. Encountered an error. Please try again!', icon="ðŸš¨")

elif app_mode == "Upscaling":
    st.markdown("# Stable Diffusion Version 2 - Image Up Scaling")
    uploaded_file = st.file_uploader(
        "Upload a image",
        type=["jpg", "jpeg", "png"],
    )
    if uploaded_file:
        # upload inmage
        image = Image.open(uploaded_file)
        w, h = image.size
        st.info(f"Loaded input image of size ({w}, {h})", icon="â„¹ï¸")
        st.image(image)
        # get prompt from user
        st.write(
            f"\n Tip: Add a description of the object that should be upscaled, e.g.: 'a professional photograph of a cat'"
        )
        prompt = st.text_input("Prompt", "a high quality professional photograph")
        c1, c2 = st.columns([1, 1], gap="small")
        with c1:
            seed = st.number_input("Seed", min_value=1, max_value=1000000, value=42)
        with c2:
            num_samples = st.number_input(
            "Number of Samples", min_value=1, max_value=64, value=1
        )
        c1, c2,c3 = st.columns([1, 1,1], gap="small")
        with c1:
            scale = st.slider("Scale", min_value=0.1, max_value=30.0, value=9.0, step=0.1)
        with c2:
            steps = st.slider("DDIM Steps", min_value=2, max_value=250, value=50, step=1)
        with c3:
            eta = st.slider(
            "eta (DDIM)", min_value=0.0, max_value=1.0, value=0.0, step=0.01
        )
        run = st.button("Generate")
        if uploaded_file and run:
            # make request body and send request
            files = {"files": uploaded_file.getvalue()}
            payload = {
                "prompt": prompt,
                "samples": num_samples,
                "steps": steps,
                "seed": seed,
                "scale": scale,
                "eta": eta,
            }
            with st.spinner("Generating ..."):
                start = time.time()
                res = requests.post(
                    f"http://{port_config.model_ports.stablediff2[-1]}:8505/upscale",
                    params=payload,
                    files=files,
                )
                end = time.time()
            try:
                response = res.json()
            # get the response back that includes path to generated image
                zip_path = response["response"]["image"]
                st.success('Successful!')
                payload = {
                    "req_type": "Stable Diffusion version2 - upscaling",
                    "prompt": prompt,
                    "runtime": (end - start)
                    }
                db_req = requests.post(
                f"http://{port_config.model_ports.db[-1]}:8509/insert",
                data=json.dumps(payload),
            )
                filename_list = glob(os.path.join(zip_path, "*.png"))
                for filename in filename_list:
                    im = Image.open(filename)
                    st.image(image)
                # enable users to download generated images
                with open(zip_path + ".zip", "rb") as file:
                    btn = st.download_button(
                        label="Download Samples",
                        data=file,
                        file_name=zip_path + ".zip",
                    )
                # delete generated images and directories
                shutil.rmtree(zip_path)
                os.remove(zip_path + ".zip")
            except NameError:
                st.error('Unsuccessful. Encountered an error. Try again!', icon="ðŸš¨")
            except json.decoder.JSONDecodeError: 
                st.error('Unsuccessful. Encountered an error. Please try again!', icon="ðŸš¨")
